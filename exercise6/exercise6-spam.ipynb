{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Import regular expressions to process emails\n",
    "import re\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many email services today provide spam filters that are able to classify emails into spam and non-spam email with high accuracy. In this part of the exercise, you will use SVMs to build your own spam filter.\n",
    "\n",
    "You will be training a classifier to classify whether a given email,  x , is spam ( y=1 ) or non-spam ( y=0 ). In particular, you need to convert each email into a feature vector  x∈ℝn  . The following parts of the exercise will walk you through how such a feature vector can be constructed from an email.\n",
    "\n",
    "The dataset included for this exercise is based on a a subset of the SpamAssassin Public Corpus. For the purpose of this exercise, you will only be using the body of the email (excluding the email headers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting on a machine learning task, it is usually insightful to take a look at examples from the dataset. The figure below shows a sample email that contains a URL, an email address (at the end), numbers, and dollar amounts.\n",
    "\n",
    "<img src=\"email.png\">\n",
    "\n",
    "While many emails would contain similar types of entities (e.g., numbers, other URLs, or other email addresses), the specific entities (e.g., the specific URL or specific dollar amount) will be different in almost every email. Therefore, one method often employed in processing emails is to “normalize” these values, so that all URLs are treated the same, all numbers are treated the same, etc. For example, we could replace each URL in the email with the unique string “httpaddr” to indicate that a URL was present.\n",
    "\n",
    "This has the effect of letting the spam classifier make a classification decision based on whether any URL was present, rather than whether a specific URL was present. This typically improves the performance of a spam classifier, since spammers often randomize the URLs, and thus the odds of seeing any particular URL again in a new piece of spam is very small.\n",
    "\n",
    "In the function processEmail below, we have implemented the following email preprocessing and normalization steps:\n",
    "\n",
    "Lower-casing: The entire email is converted into lower case, so that captialization is ignored (e.g., IndIcaTE is treated the same as Indicate).\n",
    "\n",
    "Stripping HTML: All HTML tags are removed from the emails. Many emails often come with HTML formatting; we remove all the HTML tags, so that only the content remains.\n",
    "\n",
    "- <strong>Normalizing URLs:</strong> All URLs are replaced with the text “httpaddr”.\n",
    "\n",
    "- <strong>Normalizing Email Addresses:</strong> All email addresses are replaced with the text “emailaddr”.\n",
    "\n",
    "- <strong>Normalizing Numbers:</strong> All numbers are replaced with the text “number”.\n",
    "\n",
    "- <strong>Normalizing Dollars:</strong> All dollar signs ($) are replaced with the text “dollar”.\n",
    "\n",
    "- <strong>Word Stemming:</strong> Words are reduced to their stemmed form. For example, “discount”, “discounts”, “discounted” and “discounting” are all replaced with “discount”. Sometimes, the Stemmer actually strips off additional characters from the end, so “include”, “includes”, “included”, and “including” are all replaced with “includ”.\n",
    "\n",
    "- <strong>Removal of non-words:</strong> Non-words and punctuation have been removed. All white spaces (tabs, newlines, spaces) have all been trimmed to a single space character.\n",
    "\n",
    "The result of these preprocessing steps is shown in the figure below.\n",
    "\n",
    "<img src=\"email_cleaned.png\">\n",
    "\n",
    "While preprocessing has left word fragments and non-words, this form turns out to be much easier to work with for performing feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabList():\n",
    "    \"\"\"\n",
    "    Reads the fixed vocabulary list in vocab.txt and returns a cell array of the words\n",
    "    %   vocabList = GETVOCABLIST() reads the fixed vocabulary list in vocab.txt\n",
    "    %   and returns a cell array of the words in vocabList.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    vocabList = np.genfromtxt(os.path.join('Data', 'vocab.txt'), dtype=object)\n",
    "    return list(vocabList[:, 1].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PorterStemmer:\n",
    "    \"\"\"\n",
    "    Porter Stemming Algorithm\n",
    "    This is the Porter stemming algorithm, ported to Python from the\n",
    "    version coded up in ANSI C by the author. It may be be regarded\n",
    "    as canonical, in that it follows the algorithm presented in\n",
    "    Porter, 1980, An algorithm for suffix stripping, Program, Vol. 14,\n",
    "    no. 3, pp 130-137,\n",
    "    only differing from it at the points maked --DEPARTURE-- below.\n",
    "    See also http://www.tartarus.org/~martin/PorterStemmer\n",
    "    The algorithm as described in the paper could be exactly replicated\n",
    "    by adjusting the points of DEPARTURE, but this is barely necessary,\n",
    "    because (a) the points of DEPARTURE are definitely improvements, and\n",
    "    (b) no encoding of the Porter stemmer I have seen is anything like\n",
    "    as exact as this version, even with the points of DEPARTURE!\n",
    "    Vivake Gupta (v@nano.com)\n",
    "    Release 1: January 2001\n",
    "    Further adjustments by Santiago Bruno (bananabruno@gmail.com)\n",
    "    to allow word input not restricted to one word per line, leading\n",
    "    to:\n",
    "    release 2: July 2008\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The main part of the stemming algorithm starts here.\n",
    "        b is a buffer holding a word to be stemmed. The letters are in b[k0],\n",
    "        b[k0+1] ... ending at b[k]. In fact k0 = 0 in this demo program. k is\n",
    "        readjusted downwards as the stemming progresses. Zero termination is\n",
    "        not in fact used in the algorithm.\n",
    "        Note that only lower case sequences are stemmed. Forcing to lower case\n",
    "        should be done before stem(...) is called.\n",
    "        \"\"\"\n",
    "        self.b = \"\"  # buffer for word to be stemmed\n",
    "        self.k = 0\n",
    "        self.k0 = 0\n",
    "        self.j = 0   # j is a general offset into the string\n",
    "\n",
    "    def cons(self, i):\n",
    "        \"\"\"cons(i) is TRUE <=> b[i] is a consonant.\"\"\"\n",
    "        if self.b[i] in 'aeiou':\n",
    "            return 0\n",
    "        if self.b[i] == 'y':\n",
    "            if i == self.k0:\n",
    "                return 1\n",
    "            else:\n",
    "                return not self.cons(i - 1)\n",
    "        return 1\n",
    "\n",
    "    def m(self):\n",
    "        \"\"\"\n",
    "        m() measures the number of consonant sequences between k0 and j.\n",
    "        if c is a consonant sequence and v a vowel sequence, and <..>\n",
    "        indicates arbitrary presence,\n",
    "           <c><v>       gives 0\n",
    "           <c>vc<v>     gives 1\n",
    "           <c>vcvc<v>   gives 2\n",
    "           <c>vcvcvc<v> gives 3\n",
    "           ....\n",
    "        \"\"\"\n",
    "        n = 0\n",
    "        i = self.k0\n",
    "        while 1:\n",
    "            if i > self.j:\n",
    "                return n\n",
    "            if not self.cons(i):\n",
    "                break\n",
    "            i = i + 1\n",
    "        i = i + 1\n",
    "        while 1:\n",
    "            while 1:\n",
    "                if i > self.j:\n",
    "                    return n\n",
    "                if self.cons(i):\n",
    "                    break\n",
    "                i = i + 1\n",
    "            i = i + 1\n",
    "            n = n + 1\n",
    "            while 1:\n",
    "                if i > self.j:\n",
    "                    return n\n",
    "                if not self.cons(i):\n",
    "                    break\n",
    "                i = i + 1\n",
    "            i = i + 1\n",
    "\n",
    "    def vowelinstem(self):\n",
    "        \"\"\"vowelinstem() is TRUE <=> k0,...j contains a vowel\"\"\"\n",
    "        for i in range(self.k0, self.j + 1):\n",
    "            if not self.cons(i):\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def doublec(self, j):\n",
    "        \"\"\" doublec(j) is TRUE <=> j,(j-1) contain a double consonant. \"\"\"\n",
    "        if j < (self.k0 + 1):\n",
    "            return 0\n",
    "        if self.b[j] != self.b[j-1]:\n",
    "            return 0\n",
    "        return self.cons(j)\n",
    "\n",
    "    def cvc(self, i):\n",
    "        \"\"\"\n",
    "        cvc(i) is TRUE <=> i-2,i-1,i has the form consonant - vowel - consonant\n",
    "        and also if the second c is not w,x or y. this is used when trying to\n",
    "        restore an e at the end of a short  e.g.\n",
    "           cav(e), lov(e), hop(e), crim(e), but\n",
    "           snow, box, tray.\n",
    "        \"\"\"\n",
    "        if i < (self.k0 + 2) or not self.cons(i) or self.cons(i-1) or not self.cons(i-2):\n",
    "            return 0\n",
    "        ch = self.b[i]\n",
    "        if ch in 'wxy':\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    def ends(self, s):\n",
    "        \"\"\"ends(s) is TRUE <=> k0,...k ends with the string s.\"\"\"\n",
    "        length = len(s)\n",
    "        if s[length - 1] != self.b[self.k]: # tiny speed-up\n",
    "            return 0\n",
    "        if length > (self.k - self.k0 + 1):\n",
    "            return 0\n",
    "        if self.b[self.k-length+1:self.k+1] != s:\n",
    "            return 0\n",
    "        self.j = self.k - length\n",
    "        return 1\n",
    "\n",
    "    def setto(self, s):\n",
    "        \"\"\"setto(s) sets (j+1),...k to the characters in the string s, readjusting k.\"\"\"\n",
    "        length = len(s)\n",
    "        self.b = self.b[:self.j+1] + s + self.b[self.j+length+1:]\n",
    "        self.k = self.j + length\n",
    "\n",
    "    def r(self, s):\n",
    "        \"\"\"r(s) is used further down.\"\"\"\n",
    "        if self.m() > 0:\n",
    "            self.setto(s)\n",
    "\n",
    "    def step1ab(self):\n",
    "        \"\"\"step1ab() gets rid of plurals and -ed or -ing. e.g.\n",
    "           caresses  ->  caress\n",
    "           ponies    ->  poni\n",
    "           ties      ->  ti\n",
    "           caress    ->  caress\n",
    "           cats      ->  cat\n",
    "           feed      ->  feed\n",
    "           agreed    ->  agree\n",
    "           disabled  ->  disable\n",
    "           matting   ->  mat\n",
    "           mating    ->  mate\n",
    "           meeting   ->  meet\n",
    "           milling   ->  mill\n",
    "           messing   ->  mess\n",
    "           meetings  ->  meet\n",
    "        \"\"\"\n",
    "        if self.b[self.k] == 's':\n",
    "            if self.ends(\"sses\"):\n",
    "                self.k = self.k - 2\n",
    "            elif self.ends(\"ies\"):\n",
    "                self.setto(\"i\")\n",
    "            elif self.b[self.k - 1] != 's':\n",
    "                self.k = self.k - 1\n",
    "        if self.ends(\"eed\"):\n",
    "            if self.m() > 0:\n",
    "                self.k = self.k - 1\n",
    "        elif (self.ends(\"ed\") or self.ends(\"ing\")) and self.vowelinstem():\n",
    "            self.k = self.j\n",
    "            if self.ends(\"at\"):\n",
    "                self.setto(\"ate\")\n",
    "            elif self.ends(\"bl\"):\n",
    "                self.setto(\"ble\")\n",
    "            elif self.ends(\"iz\"):\n",
    "                self.setto(\"ize\")\n",
    "            elif self.doublec(self.k):\n",
    "                self.k = self.k - 1\n",
    "                ch = self.b[self.k]\n",
    "                if ch in 'lsz':\n",
    "                    self.k += 1\n",
    "            elif self.m() == 1 and self.cvc(self.k):\n",
    "                self.setto(\"e\")\n",
    "\n",
    "    def step1c(self):\n",
    "        \"\"\"step1c() turns terminal y to i when there is another vowel in the stem.\"\"\"\n",
    "        if self.ends(\"y\") and self.vowelinstem():\n",
    "            self.b = self.b[:self.k] + 'i' + self.b[self.k+1:]\n",
    "\n",
    "    def step2(self):\n",
    "        \"\"\"step2() maps double suffices to single ones.\n",
    "        so -ization ( = -ize plus -ation) maps to -ize etc. note that the\n",
    "        string before the suffix must give m() > 0.\n",
    "        \"\"\"\n",
    "        if self.b[self.k - 1] == 'a':\n",
    "            if self.ends(\"ational\"):   self.r(\"ate\")\n",
    "            elif self.ends(\"tional\"):  self.r(\"tion\")\n",
    "        elif self.b[self.k - 1] == 'c':\n",
    "            if self.ends(\"enci\"):      self.r(\"ence\")\n",
    "            elif self.ends(\"anci\"):    self.r(\"ance\")\n",
    "        elif self.b[self.k - 1] == 'e':\n",
    "            if self.ends(\"izer\"):      self.r(\"ize\")\n",
    "        elif self.b[self.k - 1] == 'l':\n",
    "            if self.ends(\"bli\"):       self.r(\"ble\") # --DEPARTURE--\n",
    "            # To match the published algorithm, replace this phrase with\n",
    "            #   if self.ends(\"abli\"):      self.r(\"able\")\n",
    "            elif self.ends(\"alli\"):    self.r(\"al\")\n",
    "            elif self.ends(\"entli\"):   self.r(\"ent\")\n",
    "            elif self.ends(\"eli\"):     self.r(\"e\")\n",
    "            elif self.ends(\"ousli\"):   self.r(\"ous\")\n",
    "        elif self.b[self.k - 1] == 'o':\n",
    "            if self.ends(\"ization\"):   self.r(\"ize\")\n",
    "            elif self.ends(\"ation\"):   self.r(\"ate\")\n",
    "            elif self.ends(\"ator\"):    self.r(\"ate\")\n",
    "        elif self.b[self.k - 1] == 's':\n",
    "            if self.ends(\"alism\"):     self.r(\"al\")\n",
    "            elif self.ends(\"iveness\"): self.r(\"ive\")\n",
    "            elif self.ends(\"fulness\"): self.r(\"ful\")\n",
    "            elif self.ends(\"ousness\"): self.r(\"ous\")\n",
    "        elif self.b[self.k - 1] == 't':\n",
    "            if self.ends(\"aliti\"):     self.r(\"al\")\n",
    "            elif self.ends(\"iviti\"):   self.r(\"ive\")\n",
    "            elif self.ends(\"biliti\"):  self.r(\"ble\")\n",
    "        elif self.b[self.k - 1] == 'g': # --DEPARTURE--\n",
    "            if self.ends(\"logi\"):      self.r(\"log\")\n",
    "        # To match the published algorithm, delete this phrase\n",
    "\n",
    "    def step3(self):\n",
    "        \"\"\"step3() dels with -ic-, -full, -ness etc. similar strategy to step2.\"\"\"\n",
    "        if self.b[self.k] == 'e':\n",
    "            if self.ends(\"icate\"):     self.r(\"ic\")\n",
    "            elif self.ends(\"ative\"):   self.r(\"\")\n",
    "            elif self.ends(\"alize\"):   self.r(\"al\")\n",
    "        elif self.b[self.k] == 'i':\n",
    "            if self.ends(\"iciti\"):     self.r(\"ic\")\n",
    "        elif self.b[self.k] == 'l':\n",
    "            if self.ends(\"ical\"):      self.r(\"ic\")\n",
    "            elif self.ends(\"ful\"):     self.r(\"\")\n",
    "        elif self.b[self.k] == 's':\n",
    "            if self.ends(\"ness\"):      self.r(\"\")\n",
    "\n",
    "    def step4(self):\n",
    "        \"\"\"step4() takes off -ant, -ence etc., in context <c>vcvc<v>.\"\"\"\n",
    "        if self.b[self.k - 1] == 'a':\n",
    "            if self.ends(\"al\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'c':\n",
    "            if self.ends(\"ance\"): pass\n",
    "            elif self.ends(\"ence\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'e':\n",
    "            if self.ends(\"er\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'i':\n",
    "            if self.ends(\"ic\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'l':\n",
    "            if self.ends(\"able\"): pass\n",
    "            elif self.ends(\"ible\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'n':\n",
    "            if self.ends(\"ant\"): pass\n",
    "            elif self.ends(\"ement\"): pass\n",
    "            elif self.ends(\"ment\"): pass\n",
    "            elif self.ends(\"ent\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'o':\n",
    "            if self.ends(\"ion\") and (self.b[self.j] == 's' or self.b[self.j] == 't'): pass\n",
    "            elif self.ends(\"ou\"): pass\n",
    "            # takes care of -ous\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 's':\n",
    "            if self.ends(\"ism\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 't':\n",
    "            if self.ends(\"ate\"): pass\n",
    "            elif self.ends(\"iti\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'u':\n",
    "            if self.ends(\"ous\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'v':\n",
    "            if self.ends(\"ive\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'z':\n",
    "            if self.ends(\"ize\"): pass\n",
    "            else: return\n",
    "        else:\n",
    "            return\n",
    "        if self.m() > 1:\n",
    "            self.k = self.j\n",
    "\n",
    "    def step5(self):\n",
    "        \"\"\"step5() removes a final -e if m() > 1, and changes -ll to -l if\n",
    "        m() > 1.\n",
    "        \"\"\"\n",
    "        self.j = self.k\n",
    "        if self.b[self.k] == 'e':\n",
    "            a = self.m()\n",
    "            if a > 1 or (a == 1 and not self.cvc(self.k-1)):\n",
    "                self.k = self.k - 1\n",
    "        if self.b[self.k] == 'l' and self.doublec(self.k) and self.m() > 1:\n",
    "            self.k = self.k -1\n",
    "\n",
    "    def stem(self, p, i=0, j=None):\n",
    "        \"\"\"In stem(p,i,j), p is a char pointer, and the string to be stemmed\n",
    "        is from p[i] to p[j] inclusive. Typically i is zero and j is the\n",
    "        offset to the last character of a string, (p[j+1] == '\\0'). The\n",
    "        stemmer adjusts the characters p[i] ... p[j] and returns the new\n",
    "        end-point of the string, k. Stemming never increases word length, so\n",
    "        i <= k <= j. To turn the stemmer into a module, declare 'stem' as\n",
    "        extern, and delete the remainder of this file.\n",
    "        \"\"\"\n",
    "        # copy the parameters into statics\n",
    "        self.b = p\n",
    "        self.k = j or len(p) - 1\n",
    "        self.k0 = i\n",
    "        if self.k <= self.k0 + 1:\n",
    "            return self.b  # --DEPARTURE--\n",
    "\n",
    "        # With this line, strings of length 1 or 2 don't go through the\n",
    "        # stemming process, although no mention is made of this in the\n",
    "        # published algorithm. Remove the line to match the published\n",
    "        # algorithm.\n",
    "\n",
    "        self.step1ab()\n",
    "        self.step1c()\n",
    "        self.step2()\n",
    "        self.step3()\n",
    "        self.step4()\n",
    "        self.step5()\n",
    "        return self.b[self.k0:self.k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEmail(email_contents, verbose=True):\n",
    "    \"\"\"\n",
    "    Preprocesses the body of an email and returns a list of indices \n",
    "    of the words contained in the email.    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    email_contents : str\n",
    "        A string containing one email. \n",
    "    \n",
    "    verbose : bool\n",
    "        If True, print the resulting email after processing.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    word_indices : list\n",
    "        A list of integers containing the index of each word in the \n",
    "        email which is also present in the vocabulary.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to add the index of word to word_indices \n",
    "    if it is in the vocabulary. At this point of the code, you have \n",
    "    a stemmed word from the email in the variable word.\n",
    "    You should look up word in the vocabulary list (vocabList). \n",
    "    If a match exists, you should add the index of the word to the word_indices\n",
    "    list. Concretely, if word = 'action', then you should\n",
    "    look up the vocabulary list to find where in vocabList\n",
    "    'action' appears. For example, if vocabList[18] =\n",
    "    'action', then, you should add 18 to the word_indices \n",
    "    vector (e.g., word_indices.append(18)).\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - vocabList[idx] returns a the word with index idx in the vocabulary list.\n",
    "    \n",
    "    - vocabList.index(word) return index of word `word` in the vocabulary list.\n",
    "      (A ValueError exception is raised if the word does not exist.)\n",
    "    \"\"\"\n",
    "    # Load Vocabulary\n",
    "    vocabList = getVocabList()\n",
    "\n",
    "    # Init return value\n",
    "    word_indices = []\n",
    "\n",
    "    # ========================== Preprocess Email ===========================\n",
    "    # Find the Headers ( \\n\\n and remove )\n",
    "    # Uncomment the following lines if you are working with raw emails with the\n",
    "    # full headers\n",
    "    # hdrstart = email_contents.find(chr(10) + chr(10))\n",
    "    # email_contents = email_contents[hdrstart:]\n",
    "\n",
    "    # Lower case\n",
    "    email_contents = email_contents.lower()\n",
    "    \n",
    "    # Strip all HTML\n",
    "    # Looks for any expression that starts with < and ends with > and replace\n",
    "    # and does not have any < or > in the tag it with a space\n",
    "    email_contents =re.compile('<[^<>]+>').sub(' ', email_contents)\n",
    "\n",
    "    # Handle Numbers\n",
    "    # Look for one or more characters between 0-9\n",
    "    email_contents = re.compile('[0-9]+').sub(' number ', email_contents)\n",
    "\n",
    "    # Handle URLS\n",
    "    # Look for strings starting with http:// or https://\n",
    "    email_contents = re.compile('(http|https)://[^\\s]*').sub(' httpaddr ', email_contents)\n",
    "\n",
    "    # Handle Email Addresses\n",
    "    # Look for strings with @ in the middle\n",
    "    email_contents = re.compile('[^\\s]+@[^\\s]+').sub(' emailaddr ', email_contents)\n",
    "    \n",
    "    # Handle $ sign\n",
    "    email_contents = re.compile('[$]+').sub(' dollar ', email_contents)\n",
    "    \n",
    "    # get rid of any punctuation\n",
    "    email_contents = re.split('[ @$/#.-:&*+=\\[\\]?!(){},''\">_<;%\\n\\r]', email_contents)\n",
    "\n",
    "    # remove any empty word string\n",
    "    email_contents = [word for word in email_contents if len(word) > 0]\n",
    "    \n",
    "    # Stem the email contents word by word\n",
    "    stemmer = PorterStemmer()\n",
    "    processed_email = []\n",
    "    for word in email_contents:\n",
    "        # Remove any remaining non alphanumeric characters in word\n",
    "        word = re.compile('[^a-zA-Z0-9]').sub('', word).strip()\n",
    "        word = stemmer.stem(word)\n",
    "        processed_email.append(word)\n",
    "\n",
    "        if len(word) < 1:\n",
    "            continue\n",
    "\n",
    "        # Look up the word in the dictionary and add to word_indices if found\n",
    "        # ====================== YOUR CODE HERE ======================\n",
    "        # find index of the word in vocabList (if Exist)\n",
    "        if word in vocabList:\n",
    "            idx = vocabList.index(word)\n",
    "    \n",
    "        # Add the index in the vector word_indices\n",
    "        word_indices.append(vocabList[idx])\n",
    "\n",
    "        # =============================================================\n",
    "\n",
    "    if verbose:\n",
    "        print('----------------')\n",
    "        print('Processed email:')\n",
    "        print('----------------')\n",
    "        print(' '.join(processed_email))\n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Processed email:\n",
      "----------------\n",
      "anyon know how much it cost to host a web portal well it depend on how mani visitor your expect thi can be anywher from less than number buck a month to a coupl of dollar number you should checkout httpaddr or perhap amazon ec number if your run someth big to unsubscrib yourself from thi mail list send an email to emailaddr\n",
      "-------------\n",
      "Word Indices:\n",
      "-------------\n",
      "['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'host', 'web', 'web', 'well', 'it', 'depend', 'on', 'how', 'mani', 'mani', 'your', 'expect', 'thi', 'can', 'be', 'anywher', 'from', 'less', 'than', 'number', 'number', 'number', 'month', 'to', 'to', 'coupl', 'of', 'dollar', 'number', 'you', 'should', 'should', 'httpaddr', 'or', 'perhap', 'perhap', 'ec', 'number', 'if', 'your', 'run', 'someth', 'big', 'to', 'unsubscrib', 'yourself', 'from', 'thi', 'mail', 'list', 'send', 'an', 'email', 'to', 'emailaddr']\n"
     ]
    }
   ],
   "source": [
    "#  To use an SVM to classify emails into Spam v.s. Non-Spam, you first need\n",
    "#  to convert each email into a vector of features. In this part, you will\n",
    "#  implement the preprocessing steps for each email. You should\n",
    "#  complete the code in processEmail.m to produce a word indices vector\n",
    "#  for a given email.\n",
    "\n",
    "# Extract Features\n",
    "with open(os.path.join('Data', 'emailSample1.txt')) as fid:\n",
    "    file_contents = fid.read()\n",
    "\n",
    "word_indices  = processEmail(file_contents)\n",
    "\n",
    "#Print Stats\n",
    "print('-------------')\n",
    "print('Word Indices:')\n",
    "print('-------------')\n",
    "print(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
